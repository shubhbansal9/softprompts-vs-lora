{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fT_lD-7sbe9"
      },
      "outputs": [],
      "source": [
        "!pip install -q peft transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "from peft import (\n",
        "    get_peft_config,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    set_peft_model_state_dict,\n",
        "    PeftType,\n",
        "    PromptEncoderConfig,\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "import torch\n",
        "\n",
        "model_name_or_path = \"roberta-large\"\n",
        "task = \"mrpc\"\n",
        "num_epochs = 20\n",
        "lr = 1e-3\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "vq7j_0ustDhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"glue\", task)\n",
        "dataset[\"train\"][0]\n",
        "{\n",
        "    \"sentence1\": 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
        "    \"sentence2\": 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
        "    \"label\": 1,\n",
        "    \"idx\": 0,\n",
        "}"
      ],
      "metadata": {
        "id": "WWl3KGQTtHO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"glue\", task)"
      ],
      "metadata": {
        "id": "86TafvUBtJzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "VQ5_2BYStNFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
        "    padding_side = \"left\"\n",
        "else:\n",
        "    padding_side = \"right\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
        "if getattr(tokenizer, \"pad_token_id\") is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # max_length=None => use the model max length (it's actually the default)\n",
        "    outputs = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, max_length=None)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "CMykMPdLtRhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"idx\", \"sentence1\", \"sentence2\"],\n",
        ")\n",
        "\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")"
      ],
      "metadata": {
        "id": "TE4QRxYwtTSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
      ],
      "metadata": {
        "id": "p2iXfZlCtU74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=20, encoder_hidden_size=128)"
      ],
      "metadata": {
        "id": "oIR8XxsxtX1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n",
        "\"trainable params: 1351938 || all params: 355662082 || trainable%: 0.38011867680626127\""
      ],
      "metadata": {
        "id": "b294SDpAtaDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"your-name/roberta-large-peft-p-tuning\",\n",
        "    learning_rate=1e-3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ],
      "metadata": {
        "id": "9njgaGYmtcBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "VzSYxmaZteHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "peft_model_id = \"smangrul/roberta-large-peft-p-tuning\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "inference_model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "model = PeftModel.from_pretrained(inference_model, peft_model_id)"
      ],
      "metadata": {
        "id": "gdXu7uAMtgEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"not equivalent\", \"equivalent\"]\n",
        "\n",
        "sentence1 = \"Coast redwood trees are the tallest trees on the planet and can grow over 300 feet tall.\"\n",
        "sentence2 = \"The coast redwood trees, which can attain a height of over 300 feet, are the tallest trees on earth.\"\n",
        "\n",
        "inputs = tokenizer(sentence1, sentence2, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "NLW5wWAJtiHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**inputs).logits\n",
        "    print(outputs)\n",
        "\n",
        "paraphrased_text = torch.softmax(outputs, dim=1).tolist()[0]\n",
        "for i in range(len(classes)):\n",
        "    print(f\"{classes[i]}: {int(round(paraphrased_text[i] * 100))}%\")\n"
      ],
      "metadata": {
        "id": "yZ0QDVTltty1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}